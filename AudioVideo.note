from moviepy.editor import *
# import numpy as np
# import cupy as cp
import torch
import cv2, math, random
from utils.file_utils import read_lines
from utils.srt_utils import parse_srt_time, srt_texts_times
from utils.txt_utils import is_text
from PIL import Image, ImageDraw, ImageFont
from moviepy.video.fx.resize import resize


class FrameClip(VideoClip):
    def __init__(self, audioFile, srtFile, size=(1920, 1080), fps=30):
        super().__init__()

        texts, times = srt_texts_times(srtFile)

        self.audioFile = audioFile
        self.audio = AudioFileClip(audioFile)
        self.duration = self.audio.duration
        self.fps = fps
        self.size = size
        self.srtFile = srtFile
        self.texts = texts
        self.times = times
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        print("texts times ... ", len(texts), len(times))

    def create_frame(self, width, height, color, opacity):
        # Create a mask frame with the specified color and opacity
        mask_frame = torch.zeros((height, width, 3), dtype=torch.uint8, device=self.device)
        # mask_frame[:, :, :3] = color  # Set RGB color
        mask_frame[:, :, 0] = color[0]
        mask_frame[:, :, 1] = color[1]
        mask_frame[:, :, 2] = color[2]
        # mask_frame[:, :, 3] = int(opacity * 255)  # Set alpha channel
        return mask_frame

    def location(self, background, frame, x, y, endY=True, endX=True):

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        toX, toY = x + fWidth, y + fHeight

        boxW = min(toX, width) - max(0, x)
        boxH = min(toY, height) - max(0, y)

        bx, by = max(0, x), max(0, y)
        fx, fy = fWidth - boxW, fHeight - boxH

        if not endX:
            fx = 0

        if not endY:
            fy = 0

        if boxW > 0 and boxH > 0:
            background[bx:bx + boxW, by:by + boxH] = frame[fx:fx + boxW, fy:fy + boxH]

    def is_image(self, name):
        images = ('.bmp', '.dib', '.png', '.jpg', '.jpeg', '.pbm', '.pgm', '.ppm', '.tif', '.tiff')
        return name.lower().endswith(images)

    def text_index(self, t):
        index = 0
        for item in self.times:
            ftime = float(item)
            if ftime > t:
                return index
            if index < (len(self.times) - 1):
                index += 1
        return index

    def ease_quart(self, x):
        return 1 - math.pow(1 - x, 5)


class FileClip(FrameClip):
    def __init__(self, textsFile, filesPath, audioFile, srtFile, size=(1920, 1080), fps=30):
        super().__init__(audioFile=audioFile, srtFile=srtFile, size=size, fps=fps)

        self.setupTexts(textsFile)
        self.setupMedias(filesPath)

    def setupTexts(self, textsFile):
        print("setup texts ... ")

        lines = read_lines(textsFile)
        count = 0
        for index in range(len(lines)):
            count += len(lines[index].strip())

        lineTimes = []
        textLines = []

        count = 0
        for index in range(len(lines)):
            text = lines[index].strip()
            start = self.times[count]

            if count == 0:
                start = 0

            for char in text:
                if is_text(char):
                    count += 1
                    textLines.append(index)

            if count >= len(self.times):
                count -= 1

            end = self.times[count]
            lineTimes.append(f'{start}:{end}')

        self.textLines = textLines
        self.lineTimes = lineTimes

        print("lines lineTimes textLines ... ", len(lines), len(lineTimes), len(textLines))

    def setupMedias(self, filesPath):
        print("setup medias ... ")
        folder = os.path.dirname(self.audioFile)
        lines = read_lines(filesPath)
        medias = []
        for line in lines:
            parts = line.split(" --> ")
            if len(parts) > 0:
                filename = parts[0].split(" ")[0]
                videoPath = os.path.join(folder, filename)
                isImage = self.is_image(filename)

                mediaIn = random.randint(1, 4)
                mediaOut = random.randint(1, 4)

                start = parse_srt_time(parts[0].split(" ")[1])
                end = parse_srt_time(parts[1])

                if isImage:
                    imageClip = ImageClip(videoPath)
                    width, height = imageClip.size[0], imageClip.size[1]
                    scaleW = self.size[0] / width
                    scaleH = self.size[1] / height

                    scale = min(scaleW, scaleH)
                    targetSize = (int(width * scale), int(height * scale))

                    videoClip = resize(imageClip, newsize=targetSize)
                    # videoClip = resize(ImageClip(videoPath), newsize=self.size)
                else:
                    videoClip = VideoFileClip(videoPath).subclip(start, end)
                    width, height = videoClip.size[0], videoClip.size[1]
                    scaleW = self.size[0] / width
                    scaleH = self.size[1] / height

                    scale = min(scaleW, scaleH)
                    targetSize = (int(width * scale), int(height * scale))

                    videoClip = videoClip.resize(newsize=targetSize)
                    # videoClip = VideoFileClip(videoPath).subclip(start, end).resize(newsize=self.size)

                medias.append((videoClip, start, end, isImage, mediaIn, mediaOut))

        self.medias = medias

    def file_frame(self, line, t):

        parts = self.lineTimes[line].split(":")
        if len(parts) > 1:
            audioStart = float(parts[0])
            audioEnd = float(parts[1])

            videoClip, videoStart, videoEnd, isImage, mediaIn, mediaOut = self.medias[line]

            fileDuration = videoEnd - videoStart
            audioDuration = audioEnd - audioStart
            ft = (t - audioStart) * fileDuration / audioDuration

            return torch.tensor(videoClip.get_frame(ft), device=self.device), (
                    t - audioStart), audioDuration, mediaIn, mediaOut

        return None

    def left_in(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        h = height - diffH // 2
        distance = int(h * (1 - quart / total))

        x = diffW // 2
        y = (distance - h) + diffH // 2

        self.location(background, frame, x, y)

    def right_in(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        h = height - diffH // 2
        distance = int(h * (1 - quart / total))

        x = diffW // 2
        y = (h - distance) + diffH // 2

        self.location(background, frame, x, y, endY=False)

    def top_in(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        w = width - diffW // 2
        distance = int(w * (1 - quart / total))

        x = (distance - w) + diffW // 2
        y = diffH // 2

        self.location(background, frame, x, y)

    def bottom_in(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        w = width - diffW // 2
        distance = int(w * (1 - quart / total))

        x = (w - distance) + diffW // 2
        y = diffH // 2

        self.location(background, frame, x, y, endX=False)

    def right_out(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        h = height - diffH // 2
        distance = int(h * (1 - quart / total))

        x = diffW // 2
        y = distance + diffH // 2

        self.location(background, frame, x, y, endY=False)

    def left_out(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        h = height - diffH // 2
        distance = int(h * (1 - quart / total))

        x = diffW // 2
        y = -distance + diffH // 2

        self.location(background, frame, x, y, endY=True)

    def top_out(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        w = width - diffW // 2
        distance = int(w * (1 - quart / total))

        x = (- distance) + diffW // 2
        y = diffH // 2

        self.location(background, frame, x, y, endX=True)

    def bottom_out(self, background, frame, ctime, duration=0.8):
        step = 0.000000001
        count = 1 / step

        ftime = count - (count * ctime / duration)

        quart = self.ease_quart(ftime)
        total = self.ease_quart(count)

        width, height = background.shape[0], background.shape[1]
        fWidth, fHeight = frame.shape[0], frame.shape[1]

        diffW = width - fWidth
        diffH = height - fHeight

        w = width - diffW // 2
        distance = int(w * (1 - quart / total))

        x = distance + diffH // 2
        y = diffH // 2

        self.location(background, frame, x, y, endX=False)

    def make_frame(self, t):
        textIndex = self.text_index(t)
        textLine = int(self.textLines[textIndex])

        width, height = self.size[0], self.size[1]
        color = (0xFF, 0xFF, 0xFF)
        opacity = 1
        background = self.create_frame(width, height, color, opacity)

        frame, ft, fd, mediaIn, mediaOut = self.file_frame(textLine, t)
        inTime = 1.2
        outTime = 0.9

        if ft <= inTime:
            if mediaIn == 1:
                self.bottom_in(background, frame, ft, duration=inTime)
            elif mediaIn == 2:
                self.top_in(background, frame, ft, duration=inTime)
            elif mediaIn == 3:
                self.right_in(background, frame, ft, duration=inTime)
            else:
                self.left_in(background, frame, ft, duration=inTime)
        elif ft >= (fd - outTime):

            if mediaOut == 1:
                self.bottom_out(background, frame, ft - (fd - outTime), duration=outTime)
            elif mediaOut == 2:
                self.top_out(background, frame, ft - (fd - outTime), duration=outTime)
            elif mediaOut == 3:
                self.right_out(background, frame, ft - (fd - outTime), duration=outTime)
            else:
                self.left_out(background, frame, ft - (fd - outTime), duration=outTime)

            # self.right_out(background, frame, ft - (fd - atime), duration=atime)
            # self.left_out(background, frame, ft - (fd - atime), duration=atime)
            # self.top_out(background, frame, ft - (fd - atime), duration=atime)
            # self.bottom_out(background, frame, ft - (fd - atime), duration=atime)
        else:

            width, height = background.shape[0], background.shape[1]
            fWidth, fHeight = frame.shape[0], frame.shape[1]
            offsetWidth = width - fWidth
            offsetHeight = height - fHeight

            # x = - fWidth // 2  # max(0, offsetWidth // 2)
            # y = - fHeight // 2  # max(0, (offsetHeight // 2))

            x = max(0, offsetWidth // 2)
            y = max(0, (offsetHeight // 2))

            self.location(background, frame, x, y)

        return background.cpu().numpy()


audioPath = "E:\\douyin\\videos\\车床介绍2.wav"
filesPath = "E:\\douyin\\videos\\车床介绍2.files"
srtPath = "E:\\douyin\\videos\\车床介绍2.srt"
textPath = "E:\\douyin\\videos\\车床介绍2.txt"

outputPath = "E:\\douyin\\videos\\车床介绍2.mp4"

videoClip = FileClip(textPath, filesPath, audioPath, srtPath)
videoClip.write_videofile(outputPath, codec='libx264', audio_codec='aac', preset="fast", threads=8,
                          ffmpeg_params=["-gpu", "cuda"])


